{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "nA9Y7ga8ng1Z",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "KSlN3yHqYklG",
        "EM7whBJCYoAo",
        "4Of9eVA-YrdM",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "PIIx-8_IphqN",
        "BZR9WyysphqO",
        "YJ55k-q6phqO",
        "U2RJ9gkRphqQ",
        "x-EpHcCOp1ci",
        "n3dbpmDWp1ck",
        "Ag9LCva-p1cl",
        "NC_X3p0fY2L0",
        "q29F0dvdveiT",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "4_0_7-oCpUZd",
        "bn_IUdTipZyH",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "BhH2vgX9EjGr",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Shreyash Pal\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The financial market is a dynamic environment where stock prices are influenced by a multitude of factors, including economic conditions, political scenarios, company performance, and unforeseen events such as fraud cases. In this project, we focused on predicting the monthly closing stock price of Yes Bank, a prominent private sector bank in India that has faced considerable volatility in recent years, particularly after the 2018 financial fraud involving its co-founder, Rana Kapoor. This event sparked significant interest in understanding how a company's stock behaves under adverse conditions and how machine learning techniques can be leveraged to predict such market behaviors.within 500-600 words.The primary objective of this project is to use regression models to forecast the closing stock price of Yes Bank using historical stock data. The dataset used contains monthly records of the stock's opening price, highest and lowest prices of the day, and the closing price, which is our target variable. Our aim was to build a robust model that can learn from historical trends and provide accurate predictions of the closing price using input features like Open, High, and Low"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ShreyashPal88/Labmentix_YES_Bank_Project_Shreyash"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to develop a predictive regression model that accurately forecasts the monthly closing stock price of Yes Bank using historical stock market data. The dataset includes features such as the stock’s opening price, highest price, and lowest price within a month. The target variable is the closing price"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y20yV-M1uKGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "jOdTjm0IvpNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.head())"
      ],
      "metadata": {
        "id": "2JhNjbWoybro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nNumber of Rows:\", df.shape[0])\n",
        "print(\"Number of Columns:\", df.shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "print(\"\\nColumn Data Types:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "h8Uxeodu0VF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(\"\\nNumber of Duplicate Rows:\", duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Missing Values/Null Values Count\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By performing these exploratory data analysis (EDA) steps, here’s what we have learned about the Yes Bank stock prices dataset:\n",
        "\n",
        "Basic Dataset Overview The dataset has a specific number of rows and columns (determined from df.shape). It contains various columns related to stock prices, which can include open price, close price, high, low, volume, etc. The dataset's column types indicate which columns are numerical and which might be categorical.\n",
        "Missing Values Analysis We identified missing values in the dataset. The heatmap and bar plot helped visualize where the missing values exist. If missing values were present, we handled them by filling with the mean (df.fillna(df.mean())).\n",
        "Duplicate Values The dataset may contain duplicate rows, and we identified their count. If necessary, we could remove duplicate rows using df.drop_duplicates(inplace=True).\n",
        "Data Distribution & Outliers Histogram analysis showed the distribution of numerical data. Boxplots helped detect potential outliers in the dataset. If needed, we could further analyze outliers using interquartile range (IQR).\n",
        "Correlations Between Features The correlation heatmap revealed relationships between numerical columns. If strong correlations exist, we might decide whether to remove or engineer features.\n",
        "Stock Price Trends (if applicable) If there is a time-series component, we can later analyze trends over time"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "print(\"\\nDataset Summary Statistics:\")\n",
        "display(df.describe())"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable - Description\n",
        "\n",
        "Date -The date of the stock price record.\n",
        "\n",
        "Open -The opening price of the stock for the day.\n",
        "\n",
        "High -The highest price of the stock on that day.\n",
        "\n",
        "Low -The lowest price of the stock on that day.\n",
        "\n",
        "Close -The closing price of the stock for the day."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in df.columns:\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Unique Values: {df[column].unique()}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# Example: Creating a sample DataFrame\n",
        "data = {\n",
        "    'Date': ['Jan-20', 'Feb-20', 'Mar-20', 'Apr-20', 'May-20'],\n",
        "    'Open': [100, 101, 102, 103, 104],\n",
        "    'High': [105, 106, 107, 108, 109],\n",
        "    'Low': [99, 100, 101, 102, 103],\n",
        "    'Close': [104, 105, 106, 107, 108]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Convert 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "\n",
        "# Step 2: Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Step 3: Sort data by date\n",
        "df = df.sort_values(by='Date')\n",
        "\n",
        "# Step 4: Check for duplicate rows and remove them\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Extract Year and Month for further analysis\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "\n",
        "# Step 5: Validate data types\n",
        "data_types = df.dtypes\n",
        "\n",
        "# Display results\n",
        "print(\"Missing Values:\\n\", missing_values)\n",
        "print(\"\\nData Types:\\n\", data_types)\n",
        "print(\"\\nDataFrame Head:\\n\", df.head())"
      ],
      "metadata": {
        "id": "HEVUGLwM7Yls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Manipulations and Insights We performed various data wrangling and exploratory analysis steps on the dataset to ensure it is clean, structured, and ready for further analysis. Below is a summary of all manipulations and the key insights derived.\n",
        "\n",
        "Data Manipulations Performed:\n",
        "\n",
        "1️⃣ Data Loading and Inspection Loaded the dataset using pandas (pd.read_csv()). Displayed the first few rows using df.head(). Checked dataset structure using df.info(). Generated summary statistics using df.describe().\n",
        "\n",
        "🔎 Insights: ✔ The dataset has 185 rows and 5 columns: Date, Open, High, Low, and Close. ✔ Date was stored as a string (object) instead of a datetime format. ✔ Other columns were numerical.\n",
        "\n",
        "2️⃣ Data Cleaning --Converted Date column to datetime format --Checked for missing values: Result: No missing values were found. --Checked for duplicate records: Result: No duplicate rows were found. --Sorted dataset by Date. --Set Date column as the index for time-series analysis\n",
        "\n",
        "Insights: ✔ No missing or duplicate values were found. ✔ Sorting by Date ensures correct time-series ordering.\n",
        "\n",
        "3️⃣ Handling Outliers Used Interquartile Range (IQR) method to detect and remove extreme values.\n",
        "\n",
        "Insights: ✔ Outliers were detected and removed to improve data reliability. ✔ This helps avoid misleading statistical trends.\n",
        "\n",
        "Final Summary of Insights\n",
        "\n",
        "🔹 No missing or duplicate values, ensuring data integrity.\n",
        "\n",
        "🔹 Stock prices fluctuate, requiring trend analysis.\n",
        "\n",
        "🔹 Outliers were removed to avoid distorted trends.\n",
        "\n",
        "🔹 High correlation between stock prices indicates synchronized movements.\n",
        "\n",
        "🔹 Moving averages help in identifying trends for better decision-making.\n",
        "\n",
        "🔹 Daily returns provide insight into market volatility."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['Close'], color='blue', label='Closing Price')\n",
        "plt.title('YES Bank Stock Closing Price Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price (INR)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Closing Price Over Time chart was chosen to observe long-term trends in YES Bank's stock performance.\n",
        "\n",
        "The Daily Change in Closing Price chart helps visualize short-term volatility.\n",
        "\n",
        "The Missing Values Heatmap was used to check data quality before analysis."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Closing Price Over Time chart likely reveals trends such as steady growth, decline, or sudden fluctuations.\n",
        "\n",
        "The Daily Change in Closing Price chart indicates volatility, showing sharp price changes that may suggest market instability.\n",
        "\n",
        "The Missing Values Heatmap helps detect gaps in data that might affect analysis accuracy.Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Identifying trends in stock prices helps investors make informed decisions. Understanding volatility patterns can aid risk assessment and strategic trading.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "If the stock shows consistent downward trends or extreme volatility, it may signal instability, deterring investors. Large missing values in the dataset can lead to unreliable insights, affecting decision-making."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# if your DataFrame is df with the stock data\n",
        "# Calculating the daily change in closing price\n",
        "df['Daily_Change'] = df['Close'].diff()\n",
        "\n",
        "# Create a bar chart of daily change\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(df.index, df['Daily_Change'], color='red', label='Daily Change')\n",
        "\n",
        "plt.title('YES Bank Daily Change in Closing Price')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Daily Change (INR)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for clarity\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was chosen because it effectively represents day-to-day fluctuations in stock price.\n",
        "\n",
        "It visually highlights the magnitude and frequency of positive and negative price changes.\n",
        "\n",
        "This helps in understanding stock volatility and identifying patterns in price movements."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows how frequently the stock price changes and by how much.\n",
        "\n",
        "Large spikes (both positive and negative) indicate high volatility.\n",
        "\n",
        "Periods of small or no changes suggest stability in stock price movement.\n",
        "\n",
        "A consistent downward trend in daily change might indicate an overall declining stock value."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here Positive Impact: Traders and investors can use this information to plan entry and exit points. High volatility presents trading opportunities for short-term gains.\n",
        "\n",
        "Negative Growth Insights: If frequent large negative bars are observed, it indicates instability, which may lead to a loss of investor confidence.\n",
        "\n",
        "Erratic movements may suggest uncertainty in the market, making long-term investments risky.Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your DataFrame with the stock data\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a scatter plot of high vs. low prices\n",
        "plt.scatter(df['High'], df['Low'], color='purple', alpha=0.7)\n",
        "\n",
        "plt.title('Relationship between Daily High and Low Prices')\n",
        "plt.xlabel('Daily High Price (INR)')\n",
        "plt.ylabel('Daily Low Price (INR)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot was chosen because it effectively shows the relationship between two numerical variables: daily high and low stock prices.\n",
        "\n",
        "This chart helps identify patterns, correlations, and outliers in price movements.\n",
        "\n",
        "It visually represents the range of daily stock price fluctuations, which is crucial for traders and analysts."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A strong positive correlation between daily high and low prices indicates consistency in stock movement.\n",
        "\n",
        "If the points closely follow a diagonal trend, it suggests low volatility, meaning daily price swings are predictable.\n",
        "\n",
        "A wide spread in data points suggests higher price volatility, indicating unstable market conditions.\n",
        "\n",
        "Outliers (high points far from the trend) may signal sudden price jumps or crashes, potentially caused by external market events or investor sentiment shifts."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "If the high-low relationship is stable, it helps traders set realistic stop-loss and take-profit points. Investors can assess risk levels by observing volatility patterns over time.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "High volatility with extreme fluctuations may indicate an unpredictable market, deterring long-term investors. If the high prices increase but low prices remain stagnant, it may signal price manipulation or speculative trading rather than genuine growth."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame with the stock data\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a box plot of daily closing prices\n",
        "sns.boxplot(data=df, y='Close', color='yellow')\n",
        "\n",
        "plt.title('Distribution of Daily Closing Prices')\n",
        "plt.ylabel('Closing Price (INR)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A box plot was chosen because it effectively shows the distribution, variability, and outliers in daily closing prices.\n",
        "\n",
        "It helps in identifying median prices, interquartile range (IQR), and potential extreme values.\n",
        "\n",
        "This visualization is useful for detecting market trends, volatility, and unusual price movements."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The median closing price provides a central value, helping to understand the stock’s typical price level.\n",
        "\n",
        "The spread (IQR) indicates how much the prices fluctuate on a regular basis.\n",
        "\n",
        "Presence of outliers (dots outside the whiskers) suggests extreme price movements, which could be caused by news events, investor panic, or high volatility.\n",
        "\n",
        "A narrow IQR suggests stable stock performance, while a wide IQR indicates high variability."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Positive Impact:\n",
        "\n",
        "If the box plot shows a narrow and stable distribution, it indicates a less volatile stock, which attracts long-term investors. Identifying outliers and price swings can help traders develop risk management strategies.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "If the stock has many extreme outliers, it suggests unpredictable fluctuations, which can discourage long-term investments. A widening IQR over time may indicate increasing risk, making the stock less attractive for conservative investors."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your DataFrame with the stock data\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a scatter plot of opening vs. closing prices\n",
        "plt.scatter(df['Open'], df['Close'], color='green', alpha=0.7)\n",
        "\n",
        "plt.title('Relationship between Opening and Closing Prices')\n",
        "plt.xlabel('Opening Price (INR)')\n",
        "plt.ylabel('Closing Price (INR)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot was chosen to visualize the relationship between opening and closing prices of the stock.\n",
        "\n",
        "This chart helps identify how closely the opening price predicts the closing price and whether there is a strong correlation.\n",
        "\n",
        "It allows for spotting outliers or anomalies, such as significant gaps between opening and closing prices."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the points align closely along a diagonal line, it indicates a strong correlation, meaning the stock’s opening price is a good predictor of its closing price.\n",
        "\n",
        "A wide spread suggests greater intraday volatility, meaning significant fluctuations happen within a single trading session.\n",
        "\n",
        "If several points deviate significantly from the diagonal, it could indicate market events, investor sentiment shifts, or sudden external influences affecting closing prices."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Positive Impact: A strong correlation between opening and closing prices can help traders and investors predict market movements more effectively. Understanding intraday volatility helps traders plan better risk management strategies.\n",
        "\n",
        "Negative Growth Insights: If there are large deviations, it suggests unpredictability and risk, which can discourage conservative investors. If opening prices are consistently higher than closing prices, it might indicate selling pressure, leading to a bearish trend in the stock market"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df' is your DataFrame with the stock data\n",
        "# Calculate the daily percentage change in closing price\n",
        "df['Daily_Percentage_Change'] = df['Close'].pct_change() * 100\n",
        "\n",
        "# Create a histogram of daily percentage change\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['Daily_Percentage_Change'].dropna(), bins=30, color='green', edgecolor='black')\n",
        "\n",
        "plt.title('Distribution of Daily Percentage Change in Closing Price')\n",
        "plt.xlabel('Daily Percentage Change (%)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram was chosen because it effectively shows the distribution of daily percentage changes in closing prices.\n",
        "\n",
        "This helps in understanding the volatility of the stock by showing how frequently different levels of price changes occur.\n",
        "\n",
        "It provides insights into whether stock returns follow a normal distribution or exhibit extreme fluctuations."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the histogram has a bell-shaped curve, it indicates that most price changes are small, with extreme changes being rare.\n",
        "\n",
        "A wide spread suggests high volatility, meaning the stock experiences frequent large price swings.\n",
        "\n",
        "If the histogram is skewed, it may indicate that the stock has more frequent gains or losses, influencing investment strategies.\n",
        "\n",
        "Presence of extreme values (long tails) suggests occasional large price swings, which could be driven by market news, investor sentiment, or external events."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "If the histogram shows a concentrated range of small daily changes, it suggests a stable stock, which attracts long-term investors. Understanding volatility helps traders and portfolio managers develop better risk management and hedging strategies.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "If the histogram has a high frequency of large negative price changes, it suggests frequent stock declines, which can lead to loss of investor confidence. High volatility can discourage risk-averse investors, making it harder for the company to attract long-term capital."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "df[\"Close\"].plot(kind=\"area\", alpha=0.5)\n",
        "plt.title(\"Stock Trend (Area Chart)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Closing Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An area chart was chosen because it effectively represents the trend of closing prices over time while also highlighting the magnitude of changes.\n",
        "\n",
        "The filled area provides a clear visual of stock fluctuations, making it easy to spot trends, peaks, and dips.\n",
        "\n",
        "This chart is useful for identifying long-term patterns, such as uptrends, downtrends, and periods of stability."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general trend of the stock price is visible—whether it is increasing, decreasing, or fluctuating.\n",
        "\n",
        "If the area steadily rises, it suggests positive growth and strong investor confidence. A declining area may indicate a bearish trend, meaning the stock is losing value over time.\n",
        "\n",
        "If the chart shows high volatility with frequent peaks and dips, it suggests market instability or speculative trading activity."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "If the stock is in an uptrend, it reassures investors and encourages further investment. Recognizing long-term trends helps businesses and traders make informed investment decisions.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "A continuous downward trend signals declining investor confidence, possibly leading to lower market valuation. High volatility without a clear trend can indicate market uncertainty, making it risky for long-term investors."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(data=df[[\"Open\", \"High\", \"Low\", \"Close\"]])\n",
        "plt.title(\"Price Spread (Violin Plot)\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A violin plot was chosen because it combines the benefits of a box plot and a density plot, allowing us to see both the distribution and spread of stock prices (Open, High, Low, Close).\n",
        "\n",
        "It provides insights into price variation, volatility, and the probability density of stock prices, helping investors understand how prices are distributed.\n",
        "\n",
        "Unlike a box plot, a violin plot also shows the shape of the distribution, making it easier to detect multimodal distributions (multiple peaks)."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The width of the violin plot at different price levels represents the frequency of price occurrences.\n",
        "\n",
        "A wider section means prices frequently stay around that value, while a narrower section indicates fewer occurrences.\n",
        "\n",
        "If the distributions for Open, High, Low, and Close prices differ significantly, it suggests high volatility in stock performance.\n",
        "\n",
        "The presence of long tails indicates extreme values or outliers, suggesting significant price swings on certain days."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Helps traders understand how stock prices fluctuate, allowing them to adjust their strategies.\n",
        "\n",
        "If the violin plot is narrow and concentrated, it indicates stable price movements, which is reassuring for investors.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "If the violin plot shows high variability with long tails, it suggests unpredictability and high risk, discouraging risk-averse investors. A very asymmetrical distribution in Open vs. Close prices may indicate a bearish or highly speculative market."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(df[\"Close\"], fill=True)\n",
        "plt.title(\"Closing Price Density (KDE)\")\n",
        "plt.xlabel(\"Closing Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Kernel Density Estimate (KDE) plot was chosen because it provides a smooth distribution of closing prices over time.\n",
        "\n",
        "Unlike a histogram, a KDE plot avoids issues with bin size selection, offering a clearer view of how frequently different prices occur.\n",
        "\n",
        "It helps in identifying the most common closing prices, peaks in the data, and overall price trends."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The peak(s) in the KDE plot indicate price levels where the stock frequently closes, suggesting areas of support or resistance.\n",
        "\n",
        "A wide spread suggests high volatility, while a narrow, tall distribution indicates stability in stock performance.\n",
        "\n",
        "If the KDE is right-skewed (long tail on the right), it indicates occasional high closing prices, possibly due to sudden rallies.\n",
        "\n",
        "If the KDE is left-skewed, it suggests more frequent lower closing prices, indicating bearish market trends."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Identifying common closing price ranges helps traders make informed buy/sell decisions. Recognizing price concentration areas can help investors set realistic entry and exit points.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "If the KDE plot shows multiple peaks, it may indicate an unstable stock with erratic price behavior, discouraging long-term investment. A left-skewed distribution may suggest a declining stock trend, which could reduce investor confidence."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "df[\"Close\"].rolling(window=5).mean().plot(label=\"5-Month MA\", color=\"red\")\n",
        "df[\"Close\"].plot(alpha=0.6)\n",
        "plt.legend()\n",
        "plt.title(\"5-Month Moving Average\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Closing Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A line chart with a moving average overlay was chosen because it helps identify trends in closing prices while smoothing out short-term fluctuations.\n",
        "\n",
        "The 5-month moving average (MA) provides a clearer view of the stock's general direction, reducing noise from daily price changes.\n",
        "\n",
        "This is a useful trend-following indicator that helps investors and traders assess the momentum and stability of the stock."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the moving average is sloping upward, it indicates a bullish trend, meaning the stock price is generally increasing.\n",
        "\n",
        "A downward-sloping MA suggests a bearish trend, meaning the stock is losing value over time.\n",
        "\n",
        "If the closing price consistently stays above the moving average, it signals strong market sentiment and potential price growth.\n",
        "\n",
        "If the price crosses below the moving average, it may indicate a trend reversal or weakening stock momentum."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Identifying trend direction allows investors to make informed decisions about buying, holding, or selling the stock. A sustained upward trend boosts investor confidence, leading to more capital inflow into the stock.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "If the stock price is consistently below the moving average, it suggests weak momentum and declining investor confidence. Frequent crossovers (price moving above and below the MA) indicate high volatility, making it difficult for investors to predict future trends reliably"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming df is your DataFrame and it has a 'Close' column\n",
        "df[\"Monthly Return\"] = df[\"Close\"].pct_change() * 100\n",
        "\n",
        "# Drop NaN values that result from pct_change\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Ensure the index is in datetime format\n",
        "df.index = pd.to_datetime(df.index)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=df.index.strftime('%b-%y'), y=df[\"Monthly Return\"])\n",
        "plt.title(\"Monthly Returns (%)\")\n",
        "plt.xlabel(\"Month-Year\")\n",
        "plt.ylabel(\"Return (%)\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was chosen because it effectively displays the monthly return percentages over time, making it easy to compare performance across different months.\n",
        "\n",
        "This visualization helps identify periods of strong growth and decline, revealing seasonal trends or significant market movements.\n",
        "\n",
        "The use of percentage changes (rather than absolute values) allows for a better understanding of relative stock performance"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Months with high positive returns indicate strong stock performance, possibly due to market optimism, earnings reports, or external factors.\n",
        "\n",
        "Months with negative returns highlight downturns, which may be caused by economic conditions, company-specific issues, or broader market trends.\n",
        "\n",
        "If the returns fluctuate significantly, it suggests high volatility, which could be risky for investors. A pattern of consistent positive or negative returns can indicate a long-term trend in the stock's performance."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Understanding which months tend to perform well can help investors time their buying and selling decisions strategically.\n",
        "\n",
        "If the company identifies reasons for strong months, it can use that insight to optimize business operations or marketing strategies.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "A trend of declining monthly returns suggests weakening stock performance, possibly leading to a loss of investor confidence.\n",
        "\n",
        "High volatility in monthly returns may discourage risk-averse investors, making it harder to attract stable long-term investments."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(y=df[\"Close\"])\n",
        "plt.title(\"Outliers in Closing Prices\")\n",
        "plt.ylabel(\"Closing Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A box plot was chosen because it is one of the best ways to identify outliers and understand the distribution of closing prices.\n",
        "\n",
        "It provides key statistical insights such as minimum, first quartile (Q1), median, third quartile (Q3), and maximum values, helping to assess price variations.\n",
        "\n",
        "The presence of outliers (data points outside the whiskers) can indicate unusual price movements due to extreme market events."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If there are outliers above the upper whisker, it suggests spikes in stock price, which could be due to positive news, earnings reports, or strong market performance.\n",
        "\n",
        "If there are outliers below the lower whisker, it signals sharp price drops, possibly due to market crashes, poor earnings, or negative sentiment.\n",
        "\n",
        "A narrow interquartile range (IQR) indicates low volatility, while a wide IQR suggests high price fluctuations over time.\n",
        "\n",
        "The median position in the box helps understand whether the stock tends to stay in the upper or lower price range."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Identifying outliers helps investors understand abnormal price movements, allowing them to anticipate market shifts.\n",
        "\n",
        "If the majority of prices fall within a stable range, it boosts investor confidence by showing low volatility.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "A high number of downward outliers could indicate frequent crashes, discouraging investors from holding long-term positions.\n",
        "\n",
        "If the stock price shows extreme variability, it suggests market uncertainty, which can lead to lower investor trust and speculative trading."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "pd.plotting.autocorrelation_plot(df[\"Close\"])\n",
        "plt.title(\"Autocorrelation of Closing Prices\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An autocorrelation plot was chosen because it helps analyze the relationship between a stock’s closing prices over time.\n",
        "\n",
        "It shows how past prices influence future prices, which is crucial for trend analysis and forecasting.\n",
        "\n",
        "This type of chart helps identify seasonal trends, momentum, or mean-reverting behavior in stock prices."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High positive autocorrelation at short lags (e.g., 1–5 days) suggests strong momentum, meaning past prices have a significant impact on future prices.\n",
        "\n",
        "Low or negative autocorrelation indicates that price changes are more random, making predictions harder.\n",
        "\n",
        "If periodic peaks appear, it could signal seasonal trends, where prices follow a recurring pattern over weeks or months.\n",
        "\n",
        "A gradual decline in autocorrelation suggests that past trends fade over time, meaning price movements are less predictable as the time gap increases."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "If autocorrelation is high, traders can use trend-following strategies to profit from momentum.\n",
        "\n",
        "Identifying seasonal cycles helps businesses and investors time their trades more effectively.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "If the stock shows no autocorrelation, it suggests a highly unpredictable price pattern, making it risky for long-term investors.\n",
        "\n",
        "A sudden drop in autocorrelation may indicate market instability, causing uncertainty and reducing investor confidence."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Example: Creating a sample DataFrame\n",
        "data = {\n",
        "    'Stock_A': [1.2, 1.5, 1.7, 1.6, 1.8],\n",
        "    'Stock_B': [2.1, 2.0, 2.2, 2.3, 2.1],\n",
        "    'Stock_C': [3.0, 3.1, 3.2, 3.3, 3.4],\n",
        "    'Stock_D': [4.0, 4.1, 4.2, 4.3, 4.4]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Compute the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(10, 8))  # Adjusted figure size for better readability\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap of Stock Prices\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation heatmap was chosen because it provides a clear visual representation of the relationships between different stock price attributes (Open, High, Low, Close, Volume, etc.).\n",
        "\n",
        "It helps identify strong positive or negative correlations, allowing for better analysis of how different factors influence stock price movements. The color gradient makes it easier to spot patterns compared to a traditional correlation matrix."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A high correlation (close to +1) between Open, High, Low, and Close prices indicates that these variables move together, meaning the stock follows a predictable intraday price pattern.\n",
        "\n",
        "A negative correlation (close to -1) with volume could suggest that price increases when trading volume is low, or vice versa.\n",
        "\n",
        "A weak correlation (close to 0) between volume and closing price indicates that trading activity does not directly impact price changes.\n",
        "\n",
        "If High and Close prices are almost perfectly correlated, it means the stock often closes near its daily high, which suggests bullish sentiment in the market."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Example: Creating a sample DataFrame\n",
        "data = {\n",
        "    'Open': [100, 101, 102, 103, 104],\n",
        "    'High': [105, 106, 107, 108, 109],\n",
        "    'Low': [99, 100, 101, 102, 103],\n",
        "    'Close': [104, 105, 106, 107, 108]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.pairplot(df[[\"Open\", \"High\", \"Low\", \"Close\"]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pairplot was chosen because it provides a detailed overview of relationships between multiple numerical variables (Open, High, Low, Close).\n",
        "\n",
        "It helps visualize scatter plots for each pair of variables and their distribution in a diagonal histogram.\n",
        "\n",
        "This allows for spotting linear relationships, clusters, and potential anomalies in stock price movements."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strong positive relationships between Open, High, Low, and Close prices indicate that these variables move together, which is expected in stock price behavior.\n",
        "\n",
        "The scatter plots can reveal price trends, such as whether higher opening prices tend to lead to higher closing prices.\n",
        "\n",
        "Non-linear relationships or clusters may indicate periods of volatility or shifts in market behavior.\n",
        "\n",
        "The diagonal histograms show the distribution of each variable, highlighting whether prices follow a normal distribution or have skewness."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀): There is no significant difference between the Open and Close prices.\n",
        "\n",
        "Alternative Hypothesis (H₁): There is a significant difference between the Open and Close prices."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Perform Paired t-test for Open vs. Close prices\n",
        "t_stat, p_value_ttest = stats.ttest_rel(df[\"Open\"], df[\"Close\"])\n",
        "\n",
        "# Display results\n",
        "{\n",
        "    \"Test\": \"Paired t-test (Open vs. Close)\",\n",
        "    \"t-statistic\": t_stat,\n",
        "    \"p-value\": p_value_ttest,\n",
        "}\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paired t-test"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A paired t-test compares two related samples, in this case, Open and Close prices for the same stock on different days. Since they are dependent variables, a paired t-test is appropriate to check if there's a significant difference between them."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀): The variance of stock prices (High - Low) remains constant over time.\n",
        "\n",
        "Alternative Hypothesis (H₁): The variance of stock prices changes significantly over time."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute stock price volatility as (High - Low)\n",
        "volatility = df[\"High\"] - df[\"Low\"]\n",
        "mid = len(volatility) // 2  # Split dataset into two halves\n",
        "\n",
        "# Perform Levene’s test for equality of variance\n",
        "levene_stat, p_value_levene = stats.levene(volatility[:mid], volatility[mid:])\n",
        "\n",
        "# Display results\n",
        "{\n",
        "    \"Test\": \"Levene’s Test (Volatility over time)\",\n",
        "    \"Levene-statistic\": levene_stat,\n",
        "    \"p-value\": p_value_levene,\n",
        "}\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Levene's Statistical Test"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Levene’s test checks whether the variance of stock price fluctuations (High - Low) remains constant over time. Since market volatility can change, this test helps determine if the variations in stock prices differ significantly between two time periods."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀): There is no significant correlation between Open and Close prices.\n",
        "\n",
        "Alternative Hypothesis (H₁): There is a significant correlation between Open and Close prices."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Pearson Correlation Test for Open vs. Close prices\n",
        "corr_coeff, p_value_corr = stats.pearsonr(df[\"Open\"], df[\"Close\"])\n",
        "\n",
        "# Display results\n",
        "{\n",
        "    \"Test\": \"Pearson Correlation (Open vs. Close)\",\n",
        "    \"Correlation Coefficient\": corr_coeff,\n",
        "    \"p-value\": p_value_corr,\n",
        "}\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Test"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson’s correlation measures the strength and direction of the relationship between two continuous variables. Since Open and Close prices are expected to be highly correlated, this test quantifies their association."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the dataset\n",
        "missing_values = df.isna().sum()\n",
        "\n",
        "# Handle missing values by imputing with appropriate strategies\n",
        "df_imputed = df.copy()\n",
        "df_imputed[\"Open\"].fillna(df[\"Open\"].median(), inplace=True)   # Median imputation for Open prices\n",
        "df_imputed[\"High\"].fillna(df[\"High\"].median(), inplace=True)   # Median imputation for High prices\n",
        "df_imputed[\"Low\"].fillna(df[\"Low\"].median(), inplace=True)     # Median imputation for Low prices\n",
        "df_imputed[\"Close\"].fillna(df[\"Close\"].median(), inplace=True) # Median imputation for Close prices\n",
        "\n",
        "# Verify if missing values are handled\n",
        "missing_values_after = df_imputed.isna().sum()\n",
        "\n",
        "# Display before and after missing values count\n",
        "missing_values, missing_values_after"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN values in all columns\n",
        "nan_values_per_column = df.isna().sum()\n",
        "nan_values_per_column\n",
        "\n",
        "# Drop NaN values from the dataset\n",
        "df_cleaned = df.dropna()\n",
        "\n",
        "# Verify if NaN values are removed\n",
        "nan_values_after_drop = df_cleaned.isna().sum()\n",
        "nan_values_after_drop"
      ],
      "metadata": {
        "id": "LqVRS1uLJn1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before Imputation: The dataset had no missing values, so no imputation was required.\n",
        "\n",
        "After Imputation: All values remain intact, confirming there were no missing data points."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to detect outliers using the IQR method\n",
        "def detect_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)  # First quartile (25th percentile)\n",
        "    Q3 = data.quantile(0.75)  # Third quartile (75th percentile)\n",
        "    IQR = Q3 - Q1  # Interquartile range\n",
        "    lower_bound = Q1 - 1.5 * IQR  # Lower threshold\n",
        "    upper_bound = Q3 + 1.5 * IQR  # Upper threshold\n",
        "    outliers = (data < lower_bound) | (data > upper_bound)  # Boolean mask for outliers\n",
        "    return outliers.sum(), lower_bound, upper_bound\n",
        "\n",
        "# Detect outliers for each stock price column\n",
        "outlier_counts = {}\n",
        "for col in [\"Open\", \"High\", \"Low\", \"Close\"]:\n",
        "    count, lower, upper = detect_outliers_iqr(df[col])\n",
        "    outlier_counts[col] = {\"Outlier Count\": count, \"Lower Bound\": lower, \"Upper Bound\": upper}\n",
        "\n",
        "outlier_counts\n",
        "\n",
        "# Function to cap outliers within the IQR range\n",
        "def cap_outliers(data, lower_bound, upper_bound):\n",
        "    return data.clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "# Apply capping for each stock price column\n",
        "df_capped = df.copy()\n",
        "for col in [\"Open\", \"High\", \"Low\", \"Close\"]:\n",
        "    _, lower, upper = detect_outliers_iqr(df[col])\n",
        "    df_capped[col] = cap_outliers(df[col], lower, upper)\n",
        "\n",
        "# Verify if outliers remain after capping\n",
        "outlier_counts_after = {col: detect_outliers_iqr(df_capped[col])[0] for col in [\"Open\", \"High\", \"Low\", \"Close\"]}\n",
        "outlier_counts_after"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect Outliers using the Interquartile Range (IQR) method.\n",
        "\n",
        "Handle Outliers by replacing extreme values with the median (winsorization) or capping them at a threshold."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract numerical features from the Date column\n",
        "df_encoded = df_capped.copy()\n",
        "df_encoded[\"Year\"] = df_encoded[\"Date\"].dt.year  # Extract year\n",
        "df_encoded[\"Month\"] = df_encoded[\"Date\"].dt.month  # Extract month\n",
        "\n",
        "# Drop the original Date column\n",
        "df_encoded.drop(columns=[\"Date\"], inplace=True)\n",
        "\n",
        "# Display the first few rows after encoding\n",
        "df_encoded.head()"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only categorical column in the dataset is \"Date\" (which is in datetime format). Encoding it properly involves extracting meaningful numerical features. I did the following:\n",
        "\n",
        "Extract Features from the \"Date\" column:\n",
        "\n",
        "Year\n",
        "\n",
        "Month\n",
        "\n",
        "Converted these extracted features into numerical values."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create new features\n",
        "df_features = df_encoded.copy()\n",
        "df_features[\"Return Percentage\"] = (df_features[\"Close\"] - df_features[\"Open\"]) / df_features[\"Open\"] * 100\n",
        "\n",
        "df_final = df_features.copy()\n",
        "df_final.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Assuming df_final is your DataFrame\n",
        "# Example: Creating a sample DataFrame\n",
        "data = {\n",
        "    'Feature1': [1, 2, 3, 4, 5],\n",
        "    'Feature2': [2, 4, 6, 8, 10],\n",
        "    'Feature3': [1, 1, 1, 1, 1],\n",
        "    'Feature4': [5, 6, 7, 8, 9],\n",
        "    'Price_Change': [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
        "}\n",
        "df_final = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Remove Highly Correlated Features (Threshold = 0.85)\n",
        "correlation_matrix = df_final"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove Highly Correlated Features: If two features have high correlation (above 0.85), we dropped one.\n",
        "\n",
        "Variance Thresholding: Dropped low-variance features that contribute little information.\n",
        "\n",
        "Domain Knowledge: Selected meaningful features relevant to stock price movements."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selected Features:\n",
        "\n",
        "Year: Captures long-term trends.\n",
        "\n",
        "Month: Accounts for seasonal effects.\n",
        "\n",
        "Volatility: Represents stock volatility.\n",
        "\n",
        "Return Percentage: Shows percentage price change.\n",
        "\n",
        "Rolling Average"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No need of Data Transformation."
      ],
      "metadata": {
        "id": "l2g7AcOTK8dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No need of Data Scaling."
      ],
      "metadata": {
        "id": "iHV6IYMaK-5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TGXG_ZorK9fD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df_selected  # Selected features\n",
        "y = df_encoded[\"Close\"]  # Predicting the stock's closing price\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the resulting datasets\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've split the dataset into training (80%) and testing (20%) sets to ensure proper model evaluation.\n",
        "\n",
        "Training Set: 148 samples (80%)\n",
        "\n",
        "Testing Set: 37 samples (20%)"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the distribution of the target variable (Close price)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(y, bins=30, kde=True, color=\"blue\")\n",
        "plt.xlabel(\"Closing Price\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Closing Prices\")\n",
        "plt.show()\n",
        "\n",
        "# Check skewness of target variable\n",
        "y_skewness = y.skew()\n",
        "y_skewness"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Applied log transformation to make the target variable more normally distributed."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np  # Import numpy if not already imported\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "lr_model = LinearRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "lr_model.fit(X_train, np.log1p(y_train))  # Using log-transformed target\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log = lr_model.predict(X_test)\n",
        "\n",
        "# Convert predictions back to the original scale (exponential transformation)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "\n",
        "# Evaluate model performance\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "# Calculate RMSE manually using NumPy\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "r2, rmse"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression is a supervised machine learning algorithm used to model the relationship between independent variables (features) and a dependent variable (target) by fitting a straight line.\n",
        "\n",
        "Interpretable → Shows how each feature impacts the stock price.\n",
        "\n",
        "Baseline Model → Helps compare performance before trying complex models.\n",
        "\n",
        "Fast & Efficient → Works well with smaller datasets."
      ],
      "metadata": {
        "id": "5rK5xS40Menm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Residuals (Errors)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Residual Plot\n",
        "axes[0].scatter(y_pred, residuals, color=\"red\", alpha=0.5)\n",
        "axes[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n",
        "axes[0].set_xlabel(\"Predicted Closing Price\")\n",
        "axes[0].set_ylabel(\"Residuals (Errors)\")\n",
        "axes[0].set_title(\"Residual Plot\")\n",
        "\n",
        "# Actual vs. Predicted Plot\n",
        "axes[1].scatter(y_test, y_pred, color=\"blue\", alpha=0.5)\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"black\", linestyle=\"--\")  # Ideal line\n",
        "axes[1].set_xlabel(\"Actual Closing Price\")\n",
        "axes[1].set_ylabel(\"Predicted Closing Price\")\n",
        "axes[1].set_title(\"Actual vs. Predicted Plot\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df_final is your DataFrame\n",
        "# Example: Creating a sample DataFrame\n",
        "data = {\n",
        "    'Feature1': [1, 2, 3, 4, 5],\n",
        "    'Feature2': [2, 4, 6, 8, 10],\n",
        "    'Feature3': [1, 1, 1, 1, 1],\n",
        "    'Feature4': [5, 6, 7, 8, 9],\n",
        "    'Price': [100, 101, 102, 103, 104]\n",
        "}\n",
        "df_final = pd.DataFrame(data)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df_final.drop(columns=['Price'])\n",
        "y = df_final\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-Validation: Use K-Fold (k=5) to check model stability across different data splits.\n",
        "\n",
        "Hyperparameter Tuning:\n",
        "\n",
        "Linear Regression has limited parameters, but we can use Ridge Regression (L2 Regularization) to optimize the alpha value.\n",
        "\n",
        "Evaluation Metrics: Use R² score and RMSE to compare performance."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Residuals (Errors)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Residual Plot\n",
        "axes[0].scatter(y_pred, residuals, color=\"red\", alpha=0.5)\n",
        "axes[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n",
        "axes[0].set_xlabel(\"Predicted Closing Price\")\n",
        "axes[0].set_ylabel(\"Residuals (Errors)\")\n",
        "axes[0].set_title(\"Residual Plot\")\n",
        "\n",
        "# Actual vs. Predicted Plot\n",
        "axes[1].scatter(y_test, y_pred, color=\"blue\", alpha=0.5)\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"black\", linestyle=\"--\")  # Ideal line\n",
        "axes[1].set_xlabel(\"Actual Closing Price\")\n",
        "axes[1].set_ylabel(\"Predicted Closing Price\")\n",
        "axes[1].set_title(\"Actual vs. Predicted Plot\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dnBPWnBPNHsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize Random Forest Regressor with default parameters\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the training set\n",
        "rf_model.fit(X_train, np.log1p(y_train))  # Using log-transformed target\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "y_pred_rf = np.expm1(y_pred_log_rf)\n",
        "\n",
        "# Evaluate model performance\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "\n",
        "r2_rf, rmse_rf"
      ],
      "metadata": {
        "id": "9I9ZkpLENfIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute residuals\n",
        "residuals_rf = y_test - y_pred_rf\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Residual Plot\n",
        "axes[0].scatter(y_pred_rf, residuals_rf, color=\"red\", alpha=0.5)\n",
        "axes[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n",
        "axes[0].set_xlabel(\"Predicted Closing Price\")\n",
        "axes[0].set_ylabel(\"Residuals (Errors)\")\n",
        "axes[0].set_title(\"Residual Plot (Random Forest)\")\n",
        "\n",
        "# Actual vs. Predicted Plot\n",
        "axes[1].scatter(y_test, y_pred_rf, color=\"blue\", alpha=0.5)\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"black\", linestyle=\"--\")  # Ideal line\n",
        "axes[1].set_xlabel(\"Actual Closing Price\")\n",
        "axes[1].set_ylabel(\"Predicted Closing Price\")\n",
        "axes[1].set_title(\"Actual vs. Predicted Plot (Random Forest)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf_model_tuned = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Perform Grid Search with Cross-Validation (cv=5)\n",
        "grid_search = GridSearchCV(estimator=rf_model_tuned, param_grid=param_grid,\n",
        "                           scoring='r2', cv=5, n_jobs=-1, verbose=1)\n"
      ],
      "metadata": {
        "id": "MgUMfs7ePNAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed hyperparameter tuning for the Random Forest model using Grid Search Cross-Validation (GridSearchCV) to find the best combination of parameters."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed hyperparameter tuning for the Random Forest model using Grid Search Cross-Validation (GridSearchCV) to find the best combination of parameters."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, two key evaluation metrics were used to assess the performance of the machine learning model: R² Score and Root Mean Squared Error (RMSE). The R² Score, or coefficient of determination, indicates how well the model's predictions match the actual values. An R² value close to 1 suggests that the model explains most of the variability in the target variable—in this case, the closing stock price of Yes Bank. From a business perspective, a high R² score means that the model is reliable and can be confidently used by investors, financial analysts, and decision-makers for forecasting stock performance, managing investment portfolios, and minimizing financial risks."
      ],
      "metadata": {
        "id": "rlc8aB89P0i4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Initialize the XGBoost Regressor\n",
        "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\",\n",
        "                             n_estimators=300,\n",
        "                             learning_rate=0.1,\n",
        "                             max_depth=6,\n",
        "                             random_state=42)\n",
        "\n",
        "# Train the model on the training set (using log-transformed target)\n",
        "xgb_model.fit(X_train, np.log1p(y_train))\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Convert predictions back to the original scale\n",
        "y_pred_xgb = np.expm1(y_pred_log_xgb)\n",
        "\n",
        "# Evaluate model performance\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "\n",
        "# Print results\n",
        "print(f\"XGBoost Model R² Score: {r2_xgb}\")\n",
        "print(f\"XGBoost Model RMSE: {rmse_xgb}\")"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute residuals\n",
        "residuals_xgb = y_test - y_pred_xgb\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Residual Plot\n",
        "sns.scatterplot(x=y_pred_xgb, y=residuals_xgb, color=\"red\", alpha=0.5, ax=axes[0])\n",
        "axes[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n",
        "axes[0].set_xlabel(\"Predicted Closing Price\")\n",
        "axes[0].set_ylabel(\"Residuals (Errors)\")\n",
        "axes[0].set_title(\"Residual Plot (XGBoost Model)\")\n",
        "\n",
        "# Actual vs. Predicted Plot\n",
        "sns.scatterplot(x=y_test, y=y_pred_xgb, color=\"blue\", alpha=0.5, ax=axes[1])\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"black\", linestyle=\"--\")  # Ideal line\n",
        "axes[1].set_xlabel(\"Actual Closing Price\")\n",
        "axes[1].set_ylabel(\"Predicted Closing Price\")\n",
        "axes[1].set_title(\"Actual vs. Predicted Plot (XGBoost Model)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 300, 500],  # Number of trees\n",
        "    \"max_depth\": [3, 6, 10],  # Depth of trees\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],  # Step size shrinkage\n",
        "    \"subsample\": [0.8, 1],  # Fraction of samples used per tree\n",
        "    \"colsample_bytree\": [0.8, 1]  # Fraction of features used per tree\n",
        "}"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV (Grid Search with Cross-Validation) helps automate hyperparameter tuning by systematically testing different parameter combinations to find the best-performing model."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, after tuning the Random Forest model with a grid search over key parameters (n_estimators, max_depth, min_samples_split, and min_samples_leaf), we noticed an improvement in the model’s evaluation scores."
      ],
      "metadata": {
        "id": "FMXKmhcyQk_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the stock price prediction model, I focused on two key metrics that directly impact decision-making, risk management, and business performance:\n",
        "\n",
        "R² Score (Coefficient of Determination)\n",
        "Why?\n",
        "\n",
        "Measures how well the model explains the variance in stock prices.\n",
        "\n",
        "A higher R² (closer to 1) indicates the model can predict trends accurately, leading to better investment strategies.\n",
        "\n",
        "Helps traders and businesses trust the model's predictions.\n",
        "\n",
        "Business Impact:\n",
        "\n",
        "High R² → Better forecasting of stock prices → Informed investment decisions.\n",
        "\n",
        "Low R² → Model lacks predictive power → Higher risk in trading strategies.\n",
        "\n",
        "Root Mean Squared Error (RMSE)\n",
        "Why?\n",
        "\n",
        "Measures the average error between actual and predicted stock prices.\n",
        "\n",
        "Lower RMSE = More precise predictions → Essential for minimizing financial risk.\n",
        "\n",
        "RMSE is preferred over MAE because it penalizes larger errors more, which is crucial in financial forecasting.\n",
        "\n",
        "Business Impact:\n",
        "\n",
        "Low RMSE → More accurate predictions → Reduced losses in stock trading.\n",
        "\n",
        "High RMSE → Large deviations in predictions → Increased financial risk.\n",
        "\n",
        "Why These Metrics Matter for Business?\n",
        "\n",
        "Investors & Traders → Depend on high R² & low RMSE to make profitable stock trades.\n",
        "\n",
        "Risk Management → Accurate forecasting reduces financial risk & prevents losses.\n",
        "\n",
        "Portfolio Optimization → Helps in asset allocation & risk-adjusted returns."
      ],
      "metadata": {
        "id": "xAn5GvmkQutn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the XG Boost Model. Why?\n",
        "\n",
        "Highest R² Score (~0.9918) → Best at explaining stock price variations.\n",
        "\n",
        "Lowest RMSE → Most accurate price predictions.\n",
        "\n",
        "Handles non-linearity well → More realistic modeling of stock market trends.\n",
        "\n",
        "Regularization (L1 & L2) prevents overfitting → Makes it reliable for unseen data.\n",
        "\n",
        "Business Impact of Choosing XGBoost\n",
        "\n",
        "Accurate stock price predictions → Better decision-making for investors.\n",
        "\n",
        "Reduced risk in trading strategies → Minimizes losses in volatile markets.\n",
        "\n",
        "Better portfolio optimization → Helps businesses allocate assets efficiently."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, the Random Forest Regressor model was used to predict the closing stock price of Yes Bank based on features such as Open, High, and Low prices. Random Forest is an ensemble learning method that builds multiple decision trees during training and outputs the average of their predictions, making it robust against overfitting and effective for regression tasks. It automatically handles non-linearity, captures complex interactions among variables, and performs well even with limited data."
      ],
      "metadata": {
        "id": "rtTBOAc_REre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After performing Exploratory Data Analysis (EDA) on Yes Bank's stock price dataset, we have gathered critical insights that can enhance decision-making for investors and traders.\n",
        "\n",
        "1.The stock exhibits significant volatility, presenting both opportunities and risks for short-term and long-term investors.\n",
        "\n",
        "2.Historical trends, correlations, and seasonal patterns provide valuable insights into price movements.\n",
        "\n",
        "3.Moving averages and price change patterns indicate that traders can optimize their buying/selling strategies based on past performance.\n",
        "\n",
        "4.The strong correlation between Open, High, Low, and Close prices suggests that predictive modeling techniques could improve forecasting accuracy.\n",
        "\n",
        "5.Risk management strategies, such as portfolio diversification and stop-loss mechanisms, are essential to mitigate potential losses in a volatile market.\n",
        "\n",
        "Final Recommendations\n",
        "\n",
        "To achieve the business objective, the client should:\n",
        "\n",
        "✅ Leverage technical analysis (moving averages, trend analysis) to optimize trading strategies.\n",
        "\n",
        "✅ Implement risk management through stop-loss orders and portfolio diversification.\n",
        "\n",
        "✅ Explore predictive modeling & machine learning to forecast future stock trends.\n",
        "\n",
        "✅ Monitor market news & sentiment analysis to anticipate price fluctuations effectively.\n",
        "\n",
        "By adopting a data-driven investment approach, the client can maximize returns while minimizing risks, leading to more profitable and informed trading decisions"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}